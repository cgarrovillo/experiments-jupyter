{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming in Python for Data Science \n",
    "\n",
    "# Assignment 7: Importing Files and the Coding Style Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s).       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Describe what Python libraries are, as well as explain when and why they are useful.\n",
    "- Identify where code can be improved concerning variable names, magic numbers, comments and whitespace.\n",
    "- Write code that is human readable and follows the black style guide.\n",
    "- Import files from other directories.\n",
    "- Use [`pytest`](https://docs.pytest.org/en/stable/) to check a function's tests.\n",
    "- When running [`pytest`](https://docs.pytest.org/en/stable/), explain how pytest finds the associated test functions.\n",
    "- Explain how the Python debugger can help rectify your code.\n",
    "\n",
    "This assignment covers [Module 7](https://prog-learn.mds.ubc.ca/en/module7) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` and the `raise NotImplementedError # No Answer - remove if you provide an answer` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries needed for this lab\n",
    "import test_assignment7 as t\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Importing libraries   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(a)** <br> {points: 1}  \n",
    "\n",
    "Import the `pandas` library and name it `pd` in the worksheet environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7a239b989f8065dc779eac5c0db120",
     "grade": false,
     "grade_id": "cell-33212a70ac92beea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f685f2f8a2ce8ecc6e254989ff98820",
     "grade": true,
     "grade_id": "cell-932eba7b75fc58b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1a(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(b)** <br> {points: 1}  \n",
    "\n",
    "Import the Altair library into the worksheet enviroment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36271cc448c00e70899b7d28563bf9bb",
     "grade": false,
     "grade_id": "cell-2fb5b8e075bbd416",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import altair as Alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61befda99759541fa776cd5b609d4863",
     "grade": true,
     "grade_id": "cell-eca513c226d7f7f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1(c)** <br> {points: 1}  \n",
    "\n",
    "From the `numpy` library, only import the `arange()` function using the keywork `from`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e04a06ede5f30fe883b4bc81409da5a4",
     "grade": false,
     "grade_id": "cell-e99cf81fa9d22012",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a8ebfc54a36aa71ca44dd915c08591d",
     "grade": true,
     "grade_id": "cell-cf28d80fe773f520",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with other files  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(a)** <br> {points: 1}  \n",
    "\n",
    "Load in the `chopped.csv` file from the data folder and save it as an object named `chopped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d5320b231dfcaedd4e56b3582c60daa",
     "grade": false,
     "grade_id": "cell-6134753661931f24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode</th>\n",
       "      <th>series_episode</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>episode_notes</th>\n",
       "      <th>air_date</th>\n",
       "      <th>judge1</th>\n",
       "      <th>judge2</th>\n",
       "      <th>judge3</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>entree</th>\n",
       "      <th>dessert</th>\n",
       "      <th>contestant1</th>\n",
       "      <th>contestant1_info</th>\n",
       "      <th>contestant2</th>\n",
       "      <th>contestant2_info</th>\n",
       "      <th>contestant3</th>\n",
       "      <th>contestant3_info</th>\n",
       "      <th>contestant4</th>\n",
       "      <th>contestant4_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Octopus, Duck, Animal Crackers\"</td>\n",
       "      <td>This is the first episode with only three offi...</td>\n",
       "      <td>January 13, 2009</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>baby octopus, bok choy, oyster sauce, smoked ...</td>\n",
       "      <td>duck breast, green onions, ginger, honey</td>\n",
       "      <td>prunes, animal crackers, cream cheese</td>\n",
       "      <td>Summer Kriegshauser</td>\n",
       "      <td>Private Chef and Nutrition Coach  New York  NY</td>\n",
       "      <td>Perry Pollaci</td>\n",
       "      <td>Private Chef and Sous chef  Bar Blanc  New Yo...</td>\n",
       "      <td>Katie Rosenhouse</td>\n",
       "      <td>Pastry Chef  Olana Restaurant  New York  NY</td>\n",
       "      <td>Sandy Davis</td>\n",
       "      <td>Catering Chef  Showstoppers Catering at Union...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Tofu, Blueberries, Oysters\"</td>\n",
       "      <td>This is the first of a few episodes with five ...</td>\n",
       "      <td>January 20, 2009</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>firm tofu, tomato paste, prosciutto</td>\n",
       "      <td>daikon, pork loin, Napa cabbage, Thai chiles,...</td>\n",
       "      <td>phyllo dough, gorgonzola cheese, pineapple ri...</td>\n",
       "      <td>Raymond Jackson</td>\n",
       "      <td>Private Caterer and Culinary Instructor  West...</td>\n",
       "      <td>Klaus Kronsteiner</td>\n",
       "      <td>Chef de cuisine  Liberty National Golf Course...</td>\n",
       "      <td>Christopher Jackson</td>\n",
       "      <td>Executive Chef and Owner  Ted and Honey  Broo...</td>\n",
       "      <td>Pippa Calland</td>\n",
       "      <td>Owner and Chef  Chef for Hire LLC  Newville  PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Avocado, Tahini, Bran Flakes\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>January 27, 2009</td>\n",
       "      <td>Aarón Sánchez</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>lump crab meat, dried shiitake mushrooms, pin...</td>\n",
       "      <td>ground beef, cannellini beans, tahini paste, ...</td>\n",
       "      <td>brioche, cantaloupe, pecans, avocados</td>\n",
       "      <td>Margaritte Malfy</td>\n",
       "      <td>Executive Chef and Co-owner  La Palapa  New Y...</td>\n",
       "      <td>Rachelle Rodwell</td>\n",
       "      <td>Chef de cuisine  SoHo Grand Hotel  New York  NY</td>\n",
       "      <td>Chris Burke</td>\n",
       "      <td>Private Chef  New York  NY</td>\n",
       "      <td>Andre Marrero</td>\n",
       "      <td>Chef tournant  L’Atelier de Joël Robuchon  Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Banana, Collard Greens, Grits\"</td>\n",
       "      <td>In the appetizer round, Chef Chuboda refused t...</td>\n",
       "      <td>February 3, 2009</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>ground beef, wonton wrappers, cream of mushro...</td>\n",
       "      <td>scallops, collard greens, anchovies, sour cream</td>\n",
       "      <td>maple syrup, black plums, almond butter, waln...</td>\n",
       "      <td>Sean Chudoba</td>\n",
       "      <td>Executive Chef  Ayza Wine Bar  New York  NY</td>\n",
       "      <td>Kyle Shadix</td>\n",
       "      <td>Chef  Registered Dietician and Culinary Consu...</td>\n",
       "      <td>Luis Gonzales</td>\n",
       "      <td>Executive Chef  Knickerbocker Bar &amp; Grill  Ne...</td>\n",
       "      <td>Einat Admony</td>\n",
       "      <td>Chef and Owner  Taïm  New York  NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>\"Yucca, Watermelon, Tortillas\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>February 10, 2009</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Alex Guarnaschelli</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>watermelon, canned sardines, pepper jack chee...</td>\n",
       "      <td>beef shoulder, yucca, raisins, ancho chiles, ...</td>\n",
       "      <td>flour tortillas, prosecco, Canadian bacon, ro...</td>\n",
       "      <td>John Keller</td>\n",
       "      <td>Personal Chef  New York  NY</td>\n",
       "      <td>Andrea Bergquist</td>\n",
       "      <td>Executive Chef  New York  NY</td>\n",
       "      <td>Ed Witt</td>\n",
       "      <td>Executive Chef / Wine Director  Bloomingdale ...</td>\n",
       "      <td>Josh Emett</td>\n",
       "      <td>Chef de cuisine  Gordon Ramsay at The London ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>563</td>\n",
       "      <td>\"Terrine Cuisine\"</td>\n",
       "      <td>Chef Jose cut himself in the first round and c...</td>\n",
       "      <td>June 23, 2020</td>\n",
       "      <td>Chris Santos</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Erik Ramirez</td>\n",
       "      <td>rabbit terrine, guanciale, spring garlic, bur...</td>\n",
       "      <td>beer ramen, sablefish, corn on the cob, lemon...</td>\n",
       "      <td>feta ice cream, pears, blueberry ketchup, cho...</td>\n",
       "      <td>Jose Luis Chavez</td>\n",
       "      <td>Chef and Owner from New York  NY</td>\n",
       "      <td>Matt Greiner</td>\n",
       "      <td>Executive Chef from Raleigh  NC</td>\n",
       "      <td>Mimi Weissenborn</td>\n",
       "      <td>Executive Chef from Harlem  NY</td>\n",
       "      <td>Nemo Bolin</td>\n",
       "      <td>Chef and Owner from Providence  RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>564</td>\n",
       "      <td>\"Time and Turmoil\"</td>\n",
       "      <td>Chef Arden forgot an ingredient in the first r...</td>\n",
       "      <td>June 30, 2020</td>\n",
       "      <td>Amanda Freitag</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>hash brown patties, Manila clams, escarole, b...</td>\n",
       "      <td>dried cuttlefish, sweetbreads, kohlrabi, beet...</td>\n",
       "      <td>boozy cranberry gelatin, cherry scones, necta...</td>\n",
       "      <td>Lindsay Smith-Rosales</td>\n",
       "      <td>Chef and Owner from Laguna Beach  CA</td>\n",
       "      <td>Arden Lewis</td>\n",
       "      <td>Executive Chef from New York  NY</td>\n",
       "      <td>Lina Zarcaro</td>\n",
       "      <td>Private Chef from Bradley Beach  NJ</td>\n",
       "      <td>Luca Annunziata</td>\n",
       "      <td>Executive Chef from Charlotte  NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>565</td>\n",
       "      <td>\"Jarring Jars\"</td>\n",
       "      <td>The guest judge in this episode was Chef Ray G...</td>\n",
       "      <td>July 7, 2020</td>\n",
       "      <td>Scott Conant</td>\n",
       "      <td>Geoffrey Zakarian</td>\n",
       "      <td>Ray Garcia</td>\n",
       "      <td>sea beans, dehydrated carrot sticks, egg coff...</td>\n",
       "      <td>lo mein cupcakes, monkfish tails, squash blos...</td>\n",
       "      <td>guava, kefir, honeycomb, pickled pig lips</td>\n",
       "      <td>May Siricharoen</td>\n",
       "      <td>Executive Chef from Los Angeles  CA</td>\n",
       "      <td>Chris Day</td>\n",
       "      <td>Executive Sous Chef from Boston  MA</td>\n",
       "      <td>Patrick McKee</td>\n",
       "      <td>Executive Chef from Portland  OR</td>\n",
       "      <td>Phillip Esteban</td>\n",
       "      <td>Research &amp; Development Chef from San Diego  CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>566</td>\n",
       "      <td>\"Cauliflower Power\"</td>\n",
       "      <td>In this unofficially vegetarian themed episode...</td>\n",
       "      <td>July 21, 2020</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Marc Murphy</td>\n",
       "      <td>Esther Choi</td>\n",
       "      <td>cauliflower avocado toast, cauliflower rice, ...</td>\n",
       "      <td>kung pao cauliflower, cauliflower gnocchi, bl...</td>\n",
       "      <td>cauliflower oatmeal, halo-halo fruit mix, red...</td>\n",
       "      <td>Manjit Manohar</td>\n",
       "      <td>Executive Sous Chef from New York  NY</td>\n",
       "      <td>Edy Massih</td>\n",
       "      <td>Private Chef and Caterer from Brooklyn  NY</td>\n",
       "      <td>Megan Marlow</td>\n",
       "      <td>Executive Chef and Owner from Los Angeles  CA</td>\n",
       "      <td>Kei Ohdera</td>\n",
       "      <td>Chef and Owner from Portland  OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>567</td>\n",
       "      <td>\"Quail Without Fail\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July 28, 2020</td>\n",
       "      <td>Chris Santos</td>\n",
       "      <td>Maneet Chauhan</td>\n",
       "      <td>Geoffrey Zacharian</td>\n",
       "      <td>gopchang, ghost pepper aioli, nopales, hominy</td>\n",
       "      <td>quail, figs in a blanket, artichokes, anchovies</td>\n",
       "      <td>chicken salt, syrniki, passion fruit, cajeta</td>\n",
       "      <td>Bryant Kryck</td>\n",
       "      <td>Executive Chef from Portland  OR</td>\n",
       "      <td>Caroline Hough</td>\n",
       "      <td>Chef de Cuisine from Philadelphia  PA</td>\n",
       "      <td>Marco Maestoso</td>\n",
       "      <td>Chef and Owner from San Diego  CA</td>\n",
       "      <td>Calin Sauvron</td>\n",
       "      <td>Executive Chef from Bethel  CT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  season_episode  series_episode                      episode_name  \\\n",
       "0         1               1               1  \"Octopus, Duck, Animal Crackers\"   \n",
       "1         1               2               2      \"Tofu, Blueberries, Oysters\"   \n",
       "2         1               3               3    \"Avocado, Tahini, Bran Flakes\"   \n",
       "3         1               4               4   \"Banana, Collard Greens, Grits\"   \n",
       "4         1               5               5    \"Yucca, Watermelon, Tortillas\"   \n",
       "..      ...             ...             ...                               ...   \n",
       "564      45               9             563                 \"Terrine Cuisine\"   \n",
       "565      45              10             564                \"Time and Turmoil\"   \n",
       "566      45              11             565                    \"Jarring Jars\"   \n",
       "567      45              12             566               \"Cauliflower Power\"   \n",
       "568      45              13             567              \"Quail Without Fail\"   \n",
       "\n",
       "                                         episode_notes           air_date  \\\n",
       "0    This is the first episode with only three offi...   January 13, 2009   \n",
       "1    This is the first of a few episodes with five ...   January 20, 2009   \n",
       "2                                                  NaN   January 27, 2009   \n",
       "3    In the appetizer round, Chef Chuboda refused t...   February 3, 2009   \n",
       "4                                                  NaN  February 10, 2009   \n",
       "..                                                 ...                ...   \n",
       "564  Chef Jose cut himself in the first round and c...      June 23, 2020   \n",
       "565  Chef Arden forgot an ingredient in the first r...      June 30, 2020   \n",
       "566  The guest judge in this episode was Chef Ray G...       July 7, 2020   \n",
       "567  In this unofficially vegetarian themed episode...      July 21, 2020   \n",
       "568                                                NaN      July 28, 2020   \n",
       "\n",
       "                judge1              judge2              judge3  \\\n",
       "0          Marc Murphy  Alex Guarnaschelli       Aarón Sánchez   \n",
       "1        Aarón Sánchez  Alex Guarnaschelli         Marc Murphy   \n",
       "2        Aarón Sánchez  Alex Guarnaschelli         Marc Murphy   \n",
       "3         Scott Conant      Amanda Freitag   Geoffrey Zakarian   \n",
       "4    Geoffrey Zakarian  Alex Guarnaschelli         Marc Murphy   \n",
       "..                 ...                 ...                 ...   \n",
       "564       Chris Santos        Scott Conant        Erik Ramirez   \n",
       "565     Amanda Freitag      Maneet Chauhan        Scott Conant   \n",
       "566       Scott Conant   Geoffrey Zakarian          Ray Garcia   \n",
       "567     Maneet Chauhan         Marc Murphy         Esther Choi   \n",
       "568       Chris Santos      Maneet Chauhan  Geoffrey Zacharian   \n",
       "\n",
       "                                             appetizer  \\\n",
       "0     baby octopus, bok choy, oyster sauce, smoked ...   \n",
       "1                 firm tofu, tomato paste, prosciutto    \n",
       "2     lump crab meat, dried shiitake mushrooms, pin...   \n",
       "3     ground beef, wonton wrappers, cream of mushro...   \n",
       "4     watermelon, canned sardines, pepper jack chee...   \n",
       "..                                                 ...   \n",
       "564   rabbit terrine, guanciale, spring garlic, bur...   \n",
       "565   hash brown patties, Manila clams, escarole, b...   \n",
       "566   sea beans, dehydrated carrot sticks, egg coff...   \n",
       "567   cauliflower avocado toast, cauliflower rice, ...   \n",
       "568     gopchang, ghost pepper aioli, nopales, hominy    \n",
       "\n",
       "                                                entree  \\\n",
       "0            duck breast, green onions, ginger, honey    \n",
       "1     daikon, pork loin, Napa cabbage, Thai chiles,...   \n",
       "2     ground beef, cannellini beans, tahini paste, ...   \n",
       "3     scallops, collard greens, anchovies, sour cream    \n",
       "4     beef shoulder, yucca, raisins, ancho chiles, ...   \n",
       "..                                                 ...   \n",
       "564   beer ramen, sablefish, corn on the cob, lemon...   \n",
       "565   dried cuttlefish, sweetbreads, kohlrabi, beet...   \n",
       "566   lo mein cupcakes, monkfish tails, squash blos...   \n",
       "567   kung pao cauliflower, cauliflower gnocchi, bl...   \n",
       "568   quail, figs in a blanket, artichokes, anchovies    \n",
       "\n",
       "                                               dessert            contestant1  \\\n",
       "0                prunes, animal crackers, cream cheese    Summer Kriegshauser   \n",
       "1     phyllo dough, gorgonzola cheese, pineapple ri...        Raymond Jackson   \n",
       "2                brioche, cantaloupe, pecans, avocados       Margaritte Malfy   \n",
       "3     maple syrup, black plums, almond butter, waln...           Sean Chudoba   \n",
       "4     flour tortillas, prosecco, Canadian bacon, ro...            John Keller   \n",
       "..                                                 ...                    ...   \n",
       "564   feta ice cream, pears, blueberry ketchup, cho...       Jose Luis Chavez   \n",
       "565   boozy cranberry gelatin, cherry scones, necta...  Lindsay Smith-Rosales   \n",
       "566          guava, kefir, honeycomb, pickled pig lips        May Siricharoen   \n",
       "567   cauliflower oatmeal, halo-halo fruit mix, red...         Manjit Manohar   \n",
       "568       chicken salt, syrniki, passion fruit, cajeta           Bryant Kryck   \n",
       "\n",
       "                                      contestant1_info         contestant2  \\\n",
       "0      Private Chef and Nutrition Coach  New York  NY        Perry Pollaci   \n",
       "1     Private Caterer and Culinary Instructor  West...   Klaus Kronsteiner   \n",
       "2     Executive Chef and Co-owner  La Palapa  New Y...    Rachelle Rodwell   \n",
       "3         Executive Chef  Ayza Wine Bar  New York  NY          Kyle Shadix   \n",
       "4                         Personal Chef  New York  NY     Andrea Bergquist   \n",
       "..                                                 ...                 ...   \n",
       "564                  Chef and Owner from New York  NY         Matt Greiner   \n",
       "565              Chef and Owner from Laguna Beach  CA          Arden Lewis   \n",
       "566               Executive Chef from Los Angeles  CA            Chris Day   \n",
       "567             Executive Sous Chef from New York  NY           Edy Massih   \n",
       "568                  Executive Chef from Portland  OR       Caroline Hough   \n",
       "\n",
       "                                      contestant2_info           contestant3  \\\n",
       "0     Private Chef and Sous chef  Bar Blanc  New Yo...      Katie Rosenhouse   \n",
       "1     Chef de cuisine  Liberty National Golf Course...   Christopher Jackson   \n",
       "2     Chef de cuisine  SoHo Grand Hotel  New York  NY            Chris Burke   \n",
       "3     Chef  Registered Dietician and Culinary Consu...         Luis Gonzales   \n",
       "4                        Executive Chef  New York  NY                Ed Witt   \n",
       "..                                                 ...                   ...   \n",
       "564                   Executive Chef from Raleigh  NC       Mimi Weissenborn   \n",
       "565                  Executive Chef from New York  NY           Lina Zarcaro   \n",
       "566               Executive Sous Chef from Boston  MA          Patrick McKee   \n",
       "567        Private Chef and Caterer from Brooklyn  NY           Megan Marlow   \n",
       "568             Chef de Cuisine from Philadelphia  PA         Marco Maestoso   \n",
       "\n",
       "                                      contestant3_info       contestant4  \\\n",
       "0         Pastry Chef  Olana Restaurant  New York  NY        Sandy Davis   \n",
       "1     Executive Chef and Owner  Ted and Honey  Broo...     Pippa Calland   \n",
       "2                          Private Chef  New York  NY      Andre Marrero   \n",
       "3     Executive Chef  Knickerbocker Bar & Grill  Ne...      Einat Admony   \n",
       "4     Executive Chef / Wine Director  Bloomingdale ...        Josh Emett   \n",
       "..                                                 ...               ...   \n",
       "564                    Executive Chef from Harlem  NY         Nemo Bolin   \n",
       "565               Private Chef from Bradley Beach  NJ    Luca Annunziata   \n",
       "566                  Executive Chef from Portland  OR    Phillip Esteban   \n",
       "567     Executive Chef and Owner from Los Angeles  CA         Kei Ohdera   \n",
       "568                 Chef and Owner from San Diego  CA      Calin Sauvron   \n",
       "\n",
       "                                      contestant4_info  \n",
       "0     Catering Chef  Showstoppers Catering at Union...  \n",
       "1     Owner and Chef  Chef for Hire LLC  Newville  PA   \n",
       "2     Chef tournant  L’Atelier de Joël Robuchon  Ne...  \n",
       "3                  Chef and Owner  Taïm  New York  NY   \n",
       "4     Chef de cuisine  Gordon Ramsay at The London ...  \n",
       "..                                                 ...  \n",
       "564                Chef and Owner from Providence  RI   \n",
       "565                 Executive Chef from Charlotte  NC   \n",
       "566    Research & Development Chef from San Diego  CA   \n",
       "567                  Chef and Owner from Portland  OR   \n",
       "568                    Executive Chef from Bethel  CT   \n",
       "\n",
       "[569 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chopped = pd.read_csv('./data/chopped.csv')\n",
    "chopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec65ca40ff824242d121b0d208b4070e",
     "grade": true,
     "grade_id": "cell-746bfa633c7af0a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2a(chopped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(b)** <br> {points: 1}  \n",
    "\n",
    "Import the the function `sample_dataframe()` (that we created in Assignment 6) from `sampling.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3390bf4c0478081f9033c3610846add3",
     "grade": false,
     "grade_id": "cell-a60b50fcb75443d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sampling import sample_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cd337866dc4a04621d25f3fbe0ebce2",
     "grade": true,
     "grade_id": "cell-635d330803423f4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2b(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(c)** <br> {points: 2}  \n",
    "\n",
    "To refresh yourself on what the function `sample_dataframe()` does, inspect the function docstring.  \n",
    "\n",
    "Which of the following is the correct way to inspect the docstring of the function `sample_dataframe()`?     \n",
    "*Hint: Try it out yourself*\n",
    "\n",
    "A) `?sample.sample_dataframe`\n",
    "\n",
    "B) `?sample.sample_dataframe()` \n",
    "\n",
    "C) `?sample_dataframe`\n",
    "\n",
    "D) `?sample_dataframe()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer2_c`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37ea0df60619ac283eb5e272a0aa8c4",
     "grade": false,
     "grade_id": "cell-7fcb41f86f7ea257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_c = \"C\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f518f3ab0ad13f24297344e661616fb",
     "grade": true,
     "grade_id": "cell-35291c2eeae630fd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msample_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouping_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Given a dataframe, return a smaller sample of the dataframe\n",
       "sampling N rows from each specified group\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : pandas.core.frame.DataFrame\n",
       "    The dataframe to sample from\n",
       "grouping_col : str\n",
       "    The column to filter our condition on\n",
       "N : int, optional\n",
       "    The number of rows to sample from each group (The default value is 1\n",
       "    which implies a single observation)\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "pandas.core.frame.DataFrame\n",
       "    The new sampled dataframe\n",
       "    \n",
       "Examples\n",
       "--------\n",
       ">>> sample_dataframe(pokemon, 'legendary'])\n",
       "    name     deck_no  attack  defense  type    gen  legendary\n",
       "411 Burmy     412     29        45      bug     4      0\n",
       "640 Tornadus  641     100       80      flying  5      1\n",
       "\u001b[0;31mFile:\u001b[0m      ~/prog-python-data-science-students/release/assignment7/sampling.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use this cell to obtain the function docstring\n",
    "?sample_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(d)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter is optional?       \n",
    "Answer the parameter name as a `str` in the object `answer2_d`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d1ef9c2fe2ed9b7c9d97ecc9146b943",
     "grade": false,
     "grade_id": "cell-e8920e5152e7e308",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_d = \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33e02e909283893e74a4671d385864b",
     "grade": true,
     "grade_id": "cell-5821de7729f52862",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2d(answer2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(e)** <br> {points: 1}  \n",
    "\n",
    "Based on the docstring, which parameter accepts data types of `str`?      \n",
    "\n",
    "Answer the parameter name as a `str` in the object `answer2_e`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0e24962220dde0237ba12efbd484be1",
     "grade": false,
     "grade_id": "cell-e676311b515dde12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_e = \"grouping_col\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b425c2b493cee2b74194928aeff2432",
     "grade": true,
     "grade_id": "cell-3fd7084db8d73672",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2e(answer2_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2(f)** <br> {points: 1}  \n",
    "\n",
    "Sample two rows from each season from the `chopped` dataframe using your function `sample_dataframe`.     \n",
    "\n",
    "Save this in an object named `chopped_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "882ac872c1be42d6674b60036e238c2c",
     "grade": false,
     "grade_id": "cell-6299480a9da3c466",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "chopped_sample = sample_dataframe(chopped, 'season', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec1de9cca0165ef824e2d7bf3b5ac1",
     "grade": true,
     "grade_id": "cell-a3352eba01015292",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2f(chopped_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Pytest\n",
    "\n",
    "We have provided you with another file called `test_sampling.py` which contains multiple functions that test if our `sample_dataframe()` function is working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(a)** <br> {points: 1}  \n",
    "\n",
    "The tests for `sample_dataframe()` are located in a different file than the function which means we will need to import the function from our `sampling.py` file at the top of `test_sampling.py`. \n",
    "\n",
    "Open `test_sampling.py` and on line 2, write code to import the `sample_dataframe()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cade35fe5e7e6d5bb01615bec546eaa",
     "grade": true,
     "grade_id": "cell-ae85375476286d96",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a179132ad8eb5bbe5f4881b9e1cf29f",
     "grade": false,
     "grade_id": "cell-6b432fa592bfb361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3(b)** <br>\n",
    "\n",
    "We are going to do things a little differently then in the lesson here. \n",
    "Using `pytest` in a jupyter notebook, we can check if all the tests in `test_sampling.py` pass using the code `!pytest test_sampling.py` in a code cell. \n",
    "\n",
    "\n",
    "Try it out in the cell below and answer the following multiple choice questions regarding the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.5, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/jupyter/prog-python-data-science-students/release/assignment7\n",
      "plugins: anyio-3.2.1, dash-1.20.0\n",
      "collected 6 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_sampling.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                  [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_sd_cherry ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_sd_cherry\u001b[39;49;00m():\n",
      "        raw = {\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m1873\u001b[39;49;00m, \u001b[94m4913\u001b[39;49;00m, \u001b[94m4801\u001b[39;49;00m, \u001b[94m4540\u001b[39;49;00m, \u001b[94m3581\u001b[39;49;00m,\n",
      "                       \u001b[94m4534\u001b[39;49;00m, \u001b[94m1934\u001b[39;49;00m, \u001b[94m4944\u001b[39;49;00m, \u001b[94m1983\u001b[39;49;00m, \u001b[94m1266\u001b[39;49;00m],\n",
      "               \u001b[33m'\u001b[39;49;00m\u001b[33mname\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mEnglish Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mHigan Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mWillow Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mYoshino Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRed Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mKindred Spirit Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mGarry Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAccolade Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSnow Goose Cherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        \u001b[33m'\u001b[39;49;00m\u001b[33mEvergreen Oak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mneighbourhood\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mSunset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mWest end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mSunset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                  \u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                                  \u001b[33m'\u001b[39;49;00m\u001b[33mWest end\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[33m'\u001b[39;49;00m\u001b[33mKitsilano\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mArbutus-ridge\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOak\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mdiameter\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[94m9.0\u001b[39;49;00m, \u001b[94m27.0\u001b[39;49;00m, \u001b[94m3.0\u001b[39;49;00m, \u001b[94m22.0\u001b[39;49;00m, \u001b[94m3.0\u001b[39;49;00m,\n",
      "                             \u001b[94m6.5\u001b[39;49;00m, \u001b[94m12.0\u001b[39;49;00m, \u001b[94m18.0\u001b[39;49;00m, \u001b[94m8.5\u001b[39;49;00m, \u001b[94m23.0\u001b[39;49;00m]}\n",
      "        helper_data = pd.DataFrame.from_dict(raw)\n",
      "    \n",
      "        sampler = sample_dataframe(helper_data, \u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)\n",
      "    \n",
      "        \u001b[90m# Tests that there are only 1 row of type \"Cherry\"\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m sampler[sampler[\u001b[33m'\u001b[39;49;00m\u001b[33mtype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33mCherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].shape[\u001b[94m0\u001b[39;49;00m] == \u001b[94m3\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mThe dataframe should only have 1 row of type \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mcherry\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: The dataframe should only have 1 row of type 'cherry'\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 1 == 3\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_sampling.py\u001b[0m:132: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED test_sampling.py::test_sd_cherry - AssertionError: The dataframe shoul...\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m5 passed\u001b[0m\u001b[31m in 0.78s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Use this code chunk to check your tests on the file test_sampling.py using pytest\n",
    "!pytest test_sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-i)** <br> {points: 1}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` passed?      \n",
    "*Assign the correct answer to an object called `tests_passed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "547fbada2f64cffe0d00e10fbe452d9a",
     "grade": false,
     "grade_id": "cell-fb3fd2b5482fdc05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_passed = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3b1813b96d691c1eaf9f317d381a525",
     "grade": true,
     "grade_id": "cell-c687047bada4fe95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3bi(tests_passed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-ii)** <br> {points: 2}  \n",
    "\n",
    "How many of the tests from `test_sampling.py` failed?      \n",
    "*Assign the correct answer to an object called `tests_failed`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a651b9fbb2e7b2a5b7300f40a4241b3f",
     "grade": false,
     "grade_id": "cell-1202fc67d62b1792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests_failed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b81476073bd44de4e8817f9093fb0d",
     "grade": true,
     "grade_id": "cell-abcdd5212ce8810c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3(b-iii)** <br> {points: 1}  \n",
    "\n",
    "Name a test that did not pass.   \n",
    "*Assign the correct answer to an object called `failed_name`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18a537e1b9d742949bb3e75ecaa94a9",
     "grade": false,
     "grade_id": "cell-67209bf44bc4b370",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "failed_name = \"test_sd_cherry\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0480cd9b22932ceeef90d6c2fb046aa5",
     "grade": true,
     "grade_id": "cell-3d2823a898a6289a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3biii(failed_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Black and Flake8 Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a)** <br>\n",
    "\n",
    "Run Flake8 on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling.py:4:43: E251 unexpected spaces around keyword / parameter equals\n",
      "sampling.py:4:45: E251 unexpected spaces around keyword / parameter equals\n",
      "sampling.py:8:1: W293 blank line contains whitespace\n",
      "sampling.py:18:1: W293 blank line contains whitespace\n",
      "sampling.py:23:1: W293 blank line contains whitespace\n",
      "sampling.py:31:1: W293 blank line contains whitespace\n",
      "sampling.py:33:1: W293 blank line contains whitespace\n",
      "sampling.py:35:1: W293 blank line contains whitespace\n",
      "sampling.py:36:35: W291 trailing whitespace\n",
      "sampling.py:37:25: E222 multiple spaces after operator\n",
      "sampling.py:39:1: W293 blank line contains whitespace\n",
      "sampling.py:41:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-i)** <br> {points: 1}  \n",
    "\n",
    "How many formatting issues did flake8 recognize in the `sampling.py` file?      \n",
    "*Assign the correct answer to an object called `answer4_ai`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d4970e87ebc89bbab5933e526bc9d56",
     "grade": false,
     "grade_id": "cell-27db9cfd0445f2ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_ai = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9cedde3d5ecbc3f9cff73e87bc888b",
     "grade": true,
     "grade_id": "cell-da78b4046f2a5291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4ai(answer4_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-ii)** <br> {points: 1}  \n",
    "\n",
    "How many `W291 trailing whitespace` issues are there? (We will talk a little bit about trailing and leading white space in Module 8)       \n",
    "*Assign the correct answer to an object called `answer4_aii`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a12ea403bfdb2232c6d38b8c1b077c5",
     "grade": false,
     "grade_id": "cell-4380df8c2f16c985",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aii = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69531d3d00c1ce4dbdac5fb7d33de02e",
     "grade": true,
     "grade_id": "cell-ab23a0ce59a092f1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aii(answer4_aii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(a-iii)** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Which of the following is the formatting issue that occurs on line 36?     \n",
    "\n",
    "\n",
    "A) `E222 multiple spaces after operator`\n",
    "\n",
    "B) `W293 blank line contains whitespace`\n",
    "\n",
    "C) `W291 trailing whitespace`\n",
    "\n",
    "D) `E251 unexpected spaces around keyword / parameter equals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_aiii`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8ba94996c89f41c55e0462426fde910",
     "grade": false,
     "grade_id": "cell-4cdb5bce57b584a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_aiii = \"C\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8d3aab045252b408d7476ca95207e2",
     "grade": true,
     "grade_id": "cell-7775bd41eaf54724",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4aiii(answer4_aiii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(b)**  {points: 1}  \n",
    "\n",
    "Run `black` on our `sampling.py` file in the cell below or in the terminal and answer the questions that follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mreformatted sampling.py\u001b[0m\n",
      "\u001b[1mAll done! ✨ 🍰 ✨\u001b[0m\n",
      "\u001b[1m1 file reformatted\u001b[0m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use this cell to run black\n",
    "!black sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which code would you use in a Jupyter code cell to run Black?\n",
    "\n",
    "A) `black sampling.py`\n",
    "\n",
    "B) `!black sampling.py` \n",
    "\n",
    "C) `sampling.black()`\n",
    "\n",
    "D) `black.sampling()`\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer4_b`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84c9e855c345eac9d7fd09bd3f7f8c1f",
     "grade": false,
     "grade_id": "cell-10e4f5655e22c244",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_b = \"B\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76e0feef20e3e846229cb069767abe38",
     "grade": true,
     "grade_id": "cell-c9348b9faa589abf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4b(answer4_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4(c)** <br> {points: 2}  \n",
    "\n",
    "Now that we have reformatted our `sampling.py` file, let's rerun flake8 just as we did before as see how many of our formatting issues have been fixed and answer the question below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to run flake8\n",
    "!flake8 sampling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many formatting issues are we left with after re-runing flake8 after formatting `sampling.py` using the `black` style guide?\n",
    "\n",
    "*Assign the correct answer to an object called `answer4_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bee54132eb4c6c8c098d8c36a9eabec",
     "grade": false,
     "grade_id": "cell-a94532cb877f86ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer4_c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "602952b54c4dc96a00ec19e3e1b64280",
     "grade": true,
     "grade_id": "cell-b9a92e7037aad0c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Style Guide - Comments and Variable Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(a)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is most fitting for an object that contains a list of column names from a dataframe named `metals`? \n",
    "\n",
    "A) `metal_columns`\n",
    "\n",
    "B) `columnsfrommetaldataframe`\n",
    "\n",
    "C) `list`\n",
    "\n",
    "D) `c_metals` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_a`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea99287d09106ebc9636ea5fdb831838",
     "grade": false,
     "grade_id": "cell-f50baa637608027f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_a = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f4cacdab2a71d36acc7317f216f4a80",
     "grade": true,
     "grade_id": "cell-141b5df587a3cc3e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5a(answer5_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(b)** <br> {points: 1}  \n",
    "\n",
    "Which of the following names is the best fitting for object containing a dataframe containing different lightbulb types?\n",
    "\n",
    "A) `LIGHTBULBS`\n",
    "\n",
    "B) `dataframe_where_lightbulbs_data_stored`\n",
    "\n",
    "C) `data`\n",
    "\n",
    "D) `lightbulb_df` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_b`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efffe815faf74591e38eb4b46312af57",
     "grade": false,
     "grade_id": "cell-1ac2beeec7f1258d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_b = \"D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2d999013dd895239cbf204bb401bb5f",
     "grade": true,
     "grade_id": "cell-5a33f1e90db1379f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5b(answer5_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(c)** <br> {points: 2}  \n",
    "\n",
    "Which of the following is NOT a reasonable comment to include in your code?\n",
    "\n",
    "A) `# Keep this line of code in, or the function will break mysteriously`\n",
    "\n",
    "B) `# Rename columns to shorter column names`\n",
    "\n",
    "C) `# This assigns all the values greater than 100 a value of 100.`\n",
    "\n",
    "D) `# TODO: Fix this next part so it's more readable and doesn't include magic numbers` \n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between \"\", assign the correct answer to an object called `answer5_c`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b780f05c3efad8ea5202822858169d",
     "grade": false,
     "grade_id": "cell-58ce14551039cefd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer5_c = \"B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc374f8eae271b873f35ee34826fc662",
     "grade": true,
     "grade_id": "cell-67d88876daa123c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note that this test has been hidden intentionally.\n",
    "# It will provide no feedback as to the correctness of your answers.\n",
    "# Thus, it is up to you to decide if your answer is sufficiently correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5(d)** <br> {points: 2}  \n",
    "\n",
    "Below is a function that plots a histogram of a specified quantitative column.\n",
    "We want you to identify the 4 poorly designed elements within this function, and rewrite/rename them to something that is more appropriate. \n",
    "\n",
    "Copy and paste the function into the cell that follows it and then make your desired changes.\n",
    "\n",
    "*Hint: The function name does not need to be changed* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "def column_histogram(data, column_name):\n",
    "    \"\"\"\n",
    "    \n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to filter\n",
    "    column_name : str\n",
    "        The column values to plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.vegalite.v4.api.Chart \n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.vegalite.v4.api.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    # This checks if the data variable is of type pd.dataframe\n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # This area is reserved for an exception which checks the column dtype of column_name, it could be useful\n",
    "    \n",
    "    cs = column_name + \":Q\"\n",
    "    \n",
    "    # This makes a histogram and plots the values of column_name frequency \n",
    "    histogram_plot_of_column_name = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X( cs, bin=True),\n",
    "                                              y='count()',\n",
    "                                    )\n",
    "    \n",
    "    # This function now returns a histogram \n",
    "    return histogram_plot_of_column_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79d4f1778c613d7ac02986673ef33e5d",
     "grade": false,
     "grade_id": "cell-4e57ff3c843e88ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def column_histogram(data, column_name):\n",
    "    \"\"\"\n",
    "    Given a dataframe, this function creates a histogram\n",
    "    of the values from a specified column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        The dataframe to create a histogram with\n",
    "    column_name : str\n",
    "        The column name whose values will be plotted\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    altair.Chart\n",
    "        the plotted histogram\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> column_histogram(chopped, \"season\")\n",
    "    altair.Chart \n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(data, pd.DataFrame): \n",
    "        raise TypeError(\"The data argument is not of type DataFrame\")   \n",
    "    \n",
    "    # Explicitly set the data type of the column axis to be Quantitative for Altair\n",
    "    column = column_name + \":Q\"\n",
    "    \n",
    "    # This makes a histogram and plots the values of column_name frequency \n",
    "    histogram = alt.Chart(data).mark_bar().encode(\n",
    "                                        alt.X( column, bin=True),\n",
    "                                              y='count()',\n",
    "                                    ) \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87ea3309c00598248532b21c9aec546",
     "grade": true,
     "grade_id": "cell-c8c1a1322f269763",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5d(column_histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- UBC's original STAT545 - [Stat545 by Jenny Bryan](https://stat545.com/)\n",
    "- MDS DSCI 523 - Data Wrangling course - [MDS's GitHub website](hhttps://ubc-mds.github.io/) \n",
    "- Chopped Dataset - [Kaggle](https://www.kaggle.com/jeffreybraun/chopped-10-years-of-episode-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Debriefing\n",
    "\n",
    "If this video is not showing up below, click on the cell and click the ▶ button in the toolbar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('hBGFNWtYoYw', width=854, height=480)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
